{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6983252,"sourceType":"datasetVersion","datasetId":4013383},{"sourceId":8262698,"sourceType":"datasetVersion","datasetId":4904445}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-29T12:03:36.069806Z","iopub.execute_input":"2024-04-29T12:03:36.070568Z","iopub.status.idle":"2024-04-29T12:03:36.620859Z","shell.execute_reply.started":"2024-04-29T12:03:36.070537Z","shell.execute_reply":"2024-04-29T12:03:36.619977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data handling\nimport pandas as pd\nimport numpy as np\n\n# Data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\n\n# Preprocessing\nfrom sklearn.model_selection import train_test_split as tts\n\n# Torch\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchinfo import summary\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights\n\n# Metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# os\nimport os\n\n# OrderedDict\nfrom collections import OrderedDict\n\n# tqdm\nfrom tqdm.auto import tqdm\n\n# Path\nfrom pathlib import Path\n\n# random\nimport random\n\n# typing\nfrom typing import Dict, List\n\n# warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:03:36.622564Z","iopub.execute_input":"2024-04-29T12:03:36.622929Z","iopub.status.idle":"2024-04-29T12:03:47.845757Z","shell.execute_reply.started":"2024-04-29T12:03:36.622904Z","shell.execute_reply":"2024-04-29T12:03:47.844940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data + EDA","metadata":{}},{"cell_type":"code","source":"# Total Images\nIMAGE_PATH = Path(\"/kaggle/input/skin-defects-acne-redness-and-bags-under-the-eyes/files\")\n\nIMAGE_PATH_LIST = list(IMAGE_PATH.glob(\"*/*/*.jpg\"))\n\nprint(f'Total Images = {len(IMAGE_PATH_LIST)}')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:03:47.846853Z","iopub.execute_input":"2024-04-29T12:03:47.847403Z","iopub.status.idle":"2024-04-29T12:03:47.893185Z","shell.execute_reply.started":"2024-04-29T12:03:47.847378Z","shell.execute_reply":"2024-04-29T12:03:47.892346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of images per class.\nclasses = os.listdir(IMAGE_PATH)\nclasses = sorted(classes)\n\nprint(\"**\" * 20)\nprint(\" \" * 10, f\"Total Classes = {len(classes)}\")\nprint(\"**\" * 20)\n\nfor c in classes:\n    total_images_class = list(Path(os.path.join(IMAGE_PATH, c)).glob(\"*/*.jpg\"))\n    print(f\"* {c}: {len(total_images_class)} images\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:03:47.895100Z","iopub.execute_input":"2024-04-29T12:03:47.895370Z","iopub.status.idle":"2024-04-29T12:03:47.938873Z","shell.execute_reply.started":"2024-04-29T12:03:47.895348Z","shell.execute_reply":"2024-04-29T12:03:47.938063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We view some images for each class.\nNUM_IMAGES = 3\n\nfig, ax = plt.subplots(nrows = len(classes), ncols = NUM_IMAGES, figsize = (10,15))\np = 0\nfor c in classes:\n    total_images_class = list(Path(os.path.join(IMAGE_PATH, c)).glob(\"*/*.jpg\"))\n    images_selected = random.choices(total_images_class, k = NUM_IMAGES)\n    \n    for i,img_path in enumerate(images_selected):\n        img_bgr = cv2.imread(str(img_path))\n        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n        ax[p,i].imshow(img_rgb)\n        ax[p,i].axis(\"off\")\n        ax[p,i].set_title(f\"Class: {c}\\nShape: {img_rgb.shape}\", fontsize = 8, fontweight = \"bold\", color = \"black\")\n        \n    p += 1\n    \nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:03:47.939917Z","iopub.execute_input":"2024-04-29T12:03:47.940181Z","iopub.status.idle":"2024-04-29T12:04:04.450386Z","shell.execute_reply.started":"2024-04-29T12:03:47.940159Z","shell.execute_reply":"2024-04-29T12:04:04.448922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's create a dataframe with two columns:\n\n#the first path call will store the paths of the images.\n#the second call label that will contain the labels of each image.images_path = [None] * len(IMAGE_PATH_LIST)\nimages_path = [None] * len(IMAGE_PATH_LIST)\nlabels = [None] * len(IMAGE_PATH_LIST)\n\nfor i,image_path in enumerate(IMAGE_PATH_LIST):\n    images_path[i] = image_path\n    labels[i] = image_path.parent.parent.stem\n    \ndf_path_and_label = pd.DataFrame({'path':images_path, \n                                  'label':labels})\ndf_path_and_label.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:04.452245Z","iopub.execute_input":"2024-04-29T12:04:04.452563Z","iopub.status.idle":"2024-04-29T12:04:04.480834Z","shell.execute_reply.started":"2024-04-29T12:04:04.452536Z","shell.execute_reply":"2024-04-29T12:04:04.480060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train 70%, valid 15%, test 15%\nSEED = 123\n\ndf_train, df_rest = tts(df_path_and_label, \n                        test_size = 0.3, \n                        random_state = SEED, \n                        stratify = df_path_and_label[\"label\"])\n\ndf_val, df_test = tts(df_rest, \n                      test_size = 0.5, \n                      random_state = SEED, \n                      stratify = df_rest[\"label\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:04.481992Z","iopub.execute_input":"2024-04-29T12:04:04.482305Z","iopub.status.idle":"2024-04-29T12:04:04.499240Z","shell.execute_reply.started":"2024-04-29T12:04:04.482279Z","shell.execute_reply":"2024-04-29T12:04:04.498377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We have to define the mapping of the classes to convert the labels to numbers.\nlabel_map = dict(zip(classes, range(0, len(classes))))\nlabel_map\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:04.500608Z","iopub.execute_input":"2024-04-29T12:04:04.500999Z","iopub.status.idle":"2024-04-29T12:04:04.508001Z","shell.execute_reply.started":"2024-04-29T12:04:04.500964Z","shell.execute_reply":"2024-04-29T12:04:04.506988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we define the transformations that we are going to apply.\nweights = ViT_B_16_Weights.DEFAULT\nauto_transforms = weights.transforms()\nauto_transforms","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:04.509197Z","iopub.execute_input":"2024-04-29T12:04:04.509469Z","iopub.status.idle":"2024-04-29T12:04:04.525196Z","shell.execute_reply.started":"2024-04-29T12:04:04.509447Z","shell.execute_reply":"2024-04-29T12:04:04.524306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df:pd.DataFrame, transforms, label_map:dict):\n        self.df = df\n        self.transforms = transforms\n        self.label_map = label_map\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        df_new = self.df.copy()\n        df_new = df_new.reset_index(drop = True)\n        df_new[\"label\"] = df_new[\"label\"].map(self.label_map)\n        image_path = df_new.iloc[idx, 0]\n        image = Image.open(image_path).convert(\"RGB\")\n        image = self.transforms(image)\n        label = df_new.iloc[idx, 1]\n        \n        return image,label","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:04.528562Z","iopub.execute_input":"2024-04-29T12:04:04.528821Z","iopub.status.idle":"2024-04-29T12:04:04.536872Z","shell.execute_reply.started":"2024-04-29T12:04:04.528799Z","shell.execute_reply":"2024-04-29T12:04:04.535981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(df_train, auto_transforms, label_map)\nvalid_dataset = CustomDataset(df_val, auto_transforms, label_map)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:04.537744Z","iopub.execute_input":"2024-04-29T12:04:04.538307Z","iopub.status.idle":"2024-04-29T12:04:04.549796Z","shell.execute_reply.started":"2024-04-29T12:04:04.538281Z","shell.execute_reply":"2024-04-29T12:04:04.548948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 1\nNUM_WORKERS = os.cpu_count()\n\ntrain_dataloader = DataLoader(dataset = train_dataset, \n                              batch_size = BATCH_SIZE, \n                              shuffle = True, \n                              num_workers = NUM_WORKERS)\nvalid_dataloader = DataLoader(dataset = valid_dataset, \n                              batch_size = BATCH_SIZE, \n                              shuffle = True, \n                              num_workers = NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:04.550843Z","iopub.execute_input":"2024-04-29T12:04:04.551169Z","iopub.status.idle":"2024-04-29T12:04:04.561932Z","shell.execute_reply.started":"2024-04-29T12:04:04.551141Z","shell.execute_reply":"2024-04-29T12:04:04.561127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's visualize the dimensions of a batch.\nbatch_images, batch_labels = next(iter(train_dataloader))\n\nbatch_images.shape, batch_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:04.562845Z","iopub.execute_input":"2024-04-29T12:04:04.563094Z","iopub.status.idle":"2024-04-29T12:04:05.176976Z","shell.execute_reply.started":"2024-04-29T12:04:04.563073Z","shell.execute_reply":"2024-04-29T12:04:05.175877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GPU\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:05.178264Z","iopub.execute_input":"2024-04-29T12:04:05.178567Z","iopub.status.idle":"2024-04-29T12:04:05.233504Z","shell.execute_reply.started":"2024-04-29T12:04:05.178538Z","shell.execute_reply":"2024-04-29T12:04:05.232502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We define the model to use with the pre-trained weights.\nmodel = vit_b_16(weights = weights)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:05.234723Z","iopub.execute_input":"2024-04-29T12:04:05.234995Z","iopub.status.idle":"2024-04-29T12:04:09.104226Z","shell.execute_reply.started":"2024-04-29T12:04:05.234965Z","shell.execute_reply":"2024-04-29T12:04:09.103256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's visualize the architecture of the model.\nsummary(model = model, \n        input_size = [1, 3, 224, 224], \n        col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"], \n        col_width = 15, \n        row_settings = [\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:09.105508Z","iopub.execute_input":"2024-04-29T12:04:09.105848Z","iopub.status.idle":"2024-04-29T12:04:10.527934Z","shell.execute_reply.started":"2024-04-29T12:04:09.105814Z","shell.execute_reply":"2024-04-29T12:04:10.527034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We are going to freeze the parameters of the conv_proj and encoder layers.","metadata":{}},{"cell_type":"code","source":"for param in model.conv_proj.parameters():\n    param.requires_grad = False\n    \nfor param in model.encoder.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.529029Z","iopub.execute_input":"2024-04-29T12:04:10.529311Z","iopub.status.idle":"2024-04-29T12:04:10.534541Z","shell.execute_reply.started":"2024-04-29T12:04:10.529287Z","shell.execute_reply":"2024-04-29T12:04:10.533559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see if the parameters were frozen.\nsummary(model = model, \n        input_size = [1,3,224,224], \n        col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"], \n        col_width = 15,\n        row_settings = [\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.535567Z","iopub.execute_input":"2024-04-29T12:04:10.535823Z","iopub.status.idle":"2024-04-29T12:04:10.589175Z","shell.execute_reply.started":"2024-04-29T12:04:10.535791Z","shell.execute_reply":"2024-04-29T12:04:10.588286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now the parameters were frozen.\n\n#### Let's visualize the last layer which we will modify the number of out_features, in this case it is the number of classes we have.","metadata":{}},{"cell_type":"code","source":"output_shape = len(classes)\n\nmodel.heads = nn.Sequential(OrderedDict([('head', nn.Linear(in_features = 768, \n                                                            out_features = output_shape))]))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.590259Z","iopub.execute_input":"2024-04-29T12:04:10.590796Z","iopub.status.idle":"2024-04-29T12:04:10.595585Z","shell.execute_reply.started":"2024-04-29T12:04:10.590765Z","shell.execute_reply":"2024-04-29T12:04:10.594826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One last time let's take a look if the last layer was modified.\nsummary(model = model, \n        input_size = [1,3,224,224], \n        col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"], \n        col_width = 15,\n        row_settings = [\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.596689Z","iopub.execute_input":"2024-04-29T12:04:10.596934Z","iopub.status.idle":"2024-04-29T12:04:10.663111Z","shell.execute_reply.started":"2024-04-29T12:04:10.596913Z","shell.execute_reply":"2024-04-29T12:04:10.662237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.01)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.664229Z","iopub.execute_input":"2024-04-29T12:04:10.664526Z","iopub.status.idle":"2024-04-29T12:04:10.670114Z","shell.execute_reply.started":"2024-04-29T12:04:10.664502Z","shell.execute_reply":"2024-04-29T12:04:10.669179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_step(model:torch.nn.Module, \n               dataloader:torch.utils.data.DataLoader, \n               loss_fn:torch.nn.Module, \n               optimizer:torch.optim.Optimizer):\n    \n    model.train()\n    \n    train_loss = 0.\n    train_accuracy = 0.\n    \n    for batch,(X,y) in enumerate(dataloader):\n        X,y = X.to(device), y.to(device)\n        optimizer.zero_grad()\n        y_pred_logit = model(X)\n        loss = loss_fn(y_pred_logit, y)\n        train_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n        y_pred_prob = torch.softmax(y_pred_logit, dim = 1)\n        y_pred_class = torch.argmax(y_pred_prob, dim = 1)\n        train_accuracy += accuracy_score(y.cpu().numpy(), \n                                         y_pred_class.detach().cpu().numpy())\n        \n    train_loss = train_loss/len(dataloader)\n    train_accuracy = train_accuracy/len(dataloader)\n    \n    return train_loss, train_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.671078Z","iopub.execute_input":"2024-04-29T12:04:10.671415Z","iopub.status.idle":"2024-04-29T12:04:10.682040Z","shell.execute_reply.started":"2024-04-29T12:04:10.671383Z","shell.execute_reply":"2024-04-29T12:04:10.681155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(filename, model, loss, epoch, optimizer, metric):\n    state = {\"filename\":filename, \n             \"model\":model.state_dict(), \n             \"loss\":loss, \n             \"epoch\":epoch, \n             \"optimizer\":optimizer.state_dict(), \n             \"metric\":metric}\n    \n    torch.save(state, filename)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.683121Z","iopub.execute_input":"2024-04-29T12:04:10.683403Z","iopub.status.idle":"2024-04-29T12:04:10.695925Z","shell.execute_reply.started":"2024-04-29T12:04:10.683374Z","shell.execute_reply":"2024-04-29T12:04:10.695119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_step(model:torch.nn.Module, \n               dataloader:torch.utils.data.DataLoader, \n               loss_fn:torch.nn.Module):\n    \n    model.eval()\n    \n    valid_loss = 0.\n    valid_accuracy = 0.\n    \n    with torch.inference_mode():\n        for batch,(X,y) in enumerate(dataloader):\n            X,y = X.to(device), y.to(device)\n            y_pred_logit = model(X)\n            loss = loss_fn(y_pred_logit, y)\n            valid_loss += loss.item()\n            \n            y_pred_prob = torch.softmax(y_pred_logit, dim = 1)\n            y_pred_class = torch.argmax(y_pred_prob, dim = 1)\n            \n            valid_accuracy += accuracy_score(y.cpu().numpy(), y_pred_class.detach().cpu().numpy())\n    valid_loss = valid_loss/len(dataloader)\n    valid_accuracy = valid_accuracy/len(dataloader)\n    \n    return valid_loss, valid_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.696940Z","iopub.execute_input":"2024-04-29T12:04:10.697536Z","iopub.status.idle":"2024-04-29T12:04:10.706065Z","shell.execute_reply.started":"2024-04-29T12:04:10.697493Z","shell.execute_reply":"2024-04-29T12:04:10.705372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model:torch.nn.Module, \n          train_dataloader:torch.utils.data.DataLoader, \n          valid_dataloader:torch.utils.data.DataLoader, \n          loss_fn:torch.nn.Module, \n          optimizer:torch.optim.Optimizer, \n          epochs:int = 10):\n    \n    results = {\"train_loss\":[], \n               \"train_accuracy\":[], \n               \"valid_loss\":[], \n               \"valid_accuracy\":[]}\n    \n    best_valid_loss = float(\"inf\")\n    \n    for epoch in tqdm(range(epochs)):\n        train_loss, train_accuracy = train_step(model = model, \n                                                dataloader = train_dataloader, \n                                                loss_fn = loss_fn, \n                                                optimizer = optimizer)\n        \n        valid_loss, valid_accuracy = valid_step(model = model, \n                                                dataloader = valid_dataloader, \n                                                loss_fn = loss_fn)\n        \n        if valid_loss < best_valid_loss:\n            best_valid_loss = valid_loss\n            file_name = \"best_model.pth\"\n            save_checkpoint(file_name, model, best_valid_loss, epoch, optimizer, valid_accuracy)\n            \n        print(f\"Epoch: {epoch + 1} | \", \n              f\"Train Loss: {train_loss:.4f} | \", \n              f\"Train Accuracy: {train_accuracy:.4f} | \", \n              f\"Valid Loss: {valid_loss:.4f} | \", \n              f\"Valid Accuracy: {valid_accuracy:.4f}\")\n        \n        results[\"train_loss\"].append(train_loss)\n        results[\"train_accuracy\"].append(train_accuracy)\n        results[\"valid_loss\"].append(valid_loss)\n        results[\"valid_accuracy\"].append(valid_accuracy)\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.707123Z","iopub.execute_input":"2024-04-29T12:04:10.707661Z","iopub.status.idle":"2024-04-29T12:04:10.722329Z","shell.execute_reply.started":"2024-04-29T12:04:10.707631Z","shell.execute_reply":"2024-04-29T12:04:10.721633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training!!!\nEPOCHS = 100\n\ntorch.cuda.manual_seed(SEED)\ntorch.manual_seed(SEED)\n\nMODEL_RESULTS = train(model.to(device), \n                      train_dataloader, \n                      valid_dataloader, \n                      loss_fn, \n                      optimizer, \n                      EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:04:10.723452Z","iopub.execute_input":"2024-04-29T12:04:10.724277Z","iopub.status.idle":"2024-04-29T12:14:41.034458Z","shell.execute_reply.started":"2024-04-29T12:04:10.724253Z","shell.execute_reply":"2024-04-29T12:14:41.033327Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to plot the loss and metric during each training epoch.\ndef loss_metric_curve_plot(model_results:Dict[str,List[float]]):\n    \n    train_loss = model_results[\"train_loss\"]\n    valid_loss = model_results[\"valid_loss\"]\n    \n    train_accuracy = [float(value) for value in model_results[\"train_accuracy\"]]\n    valid_accuracy = [float(value) for value in model_results[\"valid_accuracy\"]]\n    \n    fig,axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10,4))\n    axes = axes.flat\n    \n    axes[0].plot(train_loss, color = \"red\", label = \"Train\")\n    axes[0].plot(valid_loss, color = \"blue\", label = \"Valid\")\n    axes[0].set_title(\"CrossEntropyLoss\", fontsize = 12, fontweight = \"bold\", color = \"black\")\n    axes[0].set_xlabel(\"Epochs\", fontsize = 10, fontweight = \"bold\", color = \"black\")\n    axes[0].set_ylabel(\"Loss\", fontsize = 10, fontweight = \"bold\", color = \"black\")\n    axes[0].legend()\n    \n    axes[1].plot(train_accuracy, color = \"red\", label = \"Train\")\n    axes[1].plot(valid_accuracy, color = \"blue\", label = \"Valid\")\n    axes[1].set_title(\"Metric of performance: Accuracy\", fontsize = 12, fontweight = \"bold\", color = \"black\")\n    axes[1].set_xlabel(\"Epochs\", fontsize = 10, fontweight = \"bold\", color = \"black\")\n    axes[1].set_ylabel(\"Score\", fontsize = 10, fontweight = \"bold\", color = \"black\")\n    axes[1].legend()\n    \n    fig.tight_layout()\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:16:11.330979Z","iopub.execute_input":"2024-04-29T12:16:11.331607Z","iopub.status.idle":"2024-04-29T12:16:11.342720Z","shell.execute_reply.started":"2024-04-29T12:16:11.331569Z","shell.execute_reply":"2024-04-29T12:16:11.341710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_metric_curve_plot(MODEL_RESULTS)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:16:24.887978Z","iopub.execute_input":"2024-04-29T12:16:24.888353Z","iopub.status.idle":"2024-04-29T12:16:25.542667Z","shell.execute_reply.started":"2024-04-29T12:16:24.888324Z","shell.execute_reply":"2024-04-29T12:16:25.541731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's load the best model.\ncheckpoint_path = \"/kaggle/working/best_model.pth\"\ncheckpoint = torch.load(checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:16:54.631302Z","iopub.execute_input":"2024-04-29T12:16:54.631681Z","iopub.status.idle":"2024-04-29T12:16:54.890742Z","shell.execute_reply.started":"2024-04-29T12:16:54.631652Z","shell.execute_reply":"2024-04-29T12:16:54.889932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's look at the smallest loss, its metric and when it occurred.\nprint(f'Best Loss: {checkpoint[\"loss\"]}')\nprint(f'Epoch: {checkpoint[\"epoch\"] + 1}')\nprint(f'Best Metric: {checkpoint[\"metric\"]}')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:17:11.109664Z","iopub.execute_input":"2024-04-29T12:17:11.109990Z","iopub.status.idle":"2024-04-29T12:17:11.114967Z","shell.execute_reply.started":"2024-04-29T12:17:11.109967Z","shell.execute_reply":"2024-04-29T12:17:11.114086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"code","source":"# First of all, we create the Dataset, DataLoader\ntest_dataset = CustomDataset(df_test, auto_transforms, label_map)\ntest_dataloader = DataLoader(dataset = test_dataset, shuffle = False, num_workers = NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:17:39.395254Z","iopub.execute_input":"2024-04-29T12:17:39.395881Z","iopub.status.idle":"2024-04-29T12:17:39.400559Z","shell.execute_reply.started":"2024-04-29T12:17:39.395853Z","shell.execute_reply":"2024-04-29T12:17:39.399655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We define the model again with its respective modification.\nloaded_model = vit_b_16()\n\nloaded_model.heads = nn.Sequential(OrderedDict([('head',nn.Linear(in_features = 768, \n                                                                  out_features = output_shape))]))\n\nloaded_model.load_state_dict(checkpoint[\"model\"])\n\n# We now infer\nloaded_model.to(device)\n\nloaded_model.eval()\n\ny_pred_test = []\n\nwith torch.inference_mode():\n    for X,y in tqdm(test_dataloader):\n        X,y = X.to(device), y.to(device)\n        y_pred_logit = loaded_model(X)\n        y_pred_prob = torch.softmax(y_pred_logit, dim = 1)\n        y_pred_class = torch.argmax(y_pred_prob, dim = 1)\n        y_pred_test.append(y_pred_class.detach().cpu())","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:17:51.516134Z","iopub.execute_input":"2024-04-29T12:17:51.516486Z","iopub.status.idle":"2024-04-29T12:17:54.636996Z","shell.execute_reply.started":"2024-04-29T12:17:51.516457Z","shell.execute_reply":"2024-04-29T12:17:54.635770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test = torch.cat(y_pred_test).numpy()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:18:01.696100Z","iopub.execute_input":"2024-04-29T12:18:01.696957Z","iopub.status.idle":"2024-04-29T12:18:01.702974Z","shell.execute_reply.started":"2024-04-29T12:18:01.696901Z","shell.execute_reply":"2024-04-29T12:18:01.702082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Accuracy = {round(accuracy_score(df_test[\"label\"].map(label_map), y_pred_test), 4)}')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:18:09.953068Z","iopub.execute_input":"2024-04-29T12:18:09.953427Z","iopub.status.idle":"2024-04-29T12:18:09.963473Z","shell.execute_reply.started":"2024-04-29T12:18:09.953399Z","shell.execute_reply":"2024-04-29T12:18:09.962332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_test = confusion_matrix(df_test[\"label\"].map(label_map), y_pred_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:18:19.585082Z","iopub.execute_input":"2024-04-29T12:18:19.586008Z","iopub.status.idle":"2024-04-29T12:18:19.592976Z","shell.execute_reply.started":"2024-04-29T12:18:19.585977Z","shell.execute_reply":"2024-04-29T12:18:19.592083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(figsize = (15,4))\nsns.heatmap(confusion_matrix_test, \n            cmap = 'coolwarm', \n            annot = True, \n            annot_kws = {\"fontsize\":9, \"fontweight\":\"bold\"}, \n            linewidths = 1.2, \n            linecolor = \"black\", \n            square = True, \n            xticklabels = classes, \n            yticklabels = classes, \n            cbar = False,\n            ax = ax)\nax.set_title(\"Confusion Matrix Test\", fontsize = 10, fontweight = \"bold\", color = \"darkblue\")\nax.tick_params('x',rotation = 90)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:18:27.487256Z","iopub.execute_input":"2024-04-29T12:18:27.487958Z","iopub.status.idle":"2024-04-29T12:18:47.934964Z","shell.execute_reply.started":"2024-04-29T12:18:27.487928Z","shell.execute_reply":"2024-04-29T12:18:47.933584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Given Images Input --> Predict Class","metadata":{}},{"cell_type":"code","source":"def classify_face(left_side_path, front_side_path, right_side_path):\n    # Load model checkpoint\n    checkpoint_path = \"/kaggle/working/best_model.pth\"\n    checkpoint = torch.load(checkpoint_path)\n    \n    # Load the model architecture\n    model = vit_b_16()\n    model.heads = nn.Sequential(OrderedDict([('head',nn.Linear(in_features = 768,\n                                                              out_features = len(classes)))]))\n    \n    # Load model weights\n    model.load_state_dict(checkpoint[\"model\"])\n    \n    # Send model to device (GPU or CPU)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    \n    # Load and preprocess images\n    def preprocess_image(image_path):\n        image = cv2.imread(image_path)\n#         print(image)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (224, 224))\n        image = image / 255.0  # Normalize pixel values\n        image = np.transpose(image, (2, 0, 1))  # Transpose to (C, H, W)\n        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n        image = image.to(device)\n        return image\n    \n    left_side = preprocess_image(left_side_path)\n    front_side = preprocess_image(front_side_path)\n    right_side = preprocess_image(right_side_path)\n    \n    # Perform inference\n    with torch.no_grad():\n        outputs = model(left_side), model(front_side), model(right_side)\n        avg_output = sum(outputs) / 3\n        probabilities = torch.softmax(avg_output, dim=1)\n        predicted_label = torch.argmax(probabilities).item()\n        predicted_class = classes[predicted_label]\n    \n    return predicted_class\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:40:25.822727Z","iopub.execute_input":"2024-04-29T12:40:25.823538Z","iopub.status.idle":"2024-04-29T12:40:25.833393Z","shell.execute_reply.started":"2024-04-29T12:40:25.823508Z","shell.execute_reply":"2024-04-29T12:40:25.832541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example usage:\nleft_side_path = \"/kaggle/input/datapoint/left_side.jpg/left_side.jpg\"\nfront_side_path = \"/kaggle/input/datapoint/front.jpg/front.jpg\"\nright_side_path = \"/kaggle/input/datapoint/right_side.jpg/right_side.jpg\"\n\nresult = classify_face(left_side_path, front_side_path, right_side_path)\nprint(\"Predicted class:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:40:28.410836Z","iopub.execute_input":"2024-04-29T12:40:28.411463Z","iopub.status.idle":"2024-04-29T12:40:30.432137Z","shell.execute_reply.started":"2024-04-29T12:40:28.411432Z","shell.execute_reply":"2024-04-29T12:40:30.431087Z"},"trusted":true},"execution_count":null,"outputs":[]}]}